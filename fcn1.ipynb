{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUioOwu2NX31gvn1D9VM4j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloelee-0007/computer-vision-paper/blob/main/fcn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install BagData\n",
        "# !pip install hyo2.bag\n",
        "!pip install hyo.bagexplorer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_RHO6Pw3aSl",
        "outputId": "23d5f42b-6242-45f6-b8b3-8b8d80198201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement hyo.bagexplorer (from versions: 0.5.0, 0.5.1, 0.5.7)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for hyo.bagexplorer\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "from BagData import dataloader\n",
        "import pdb\n",
        "import numpy as np \n",
        "import time\n",
        "import visdom\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "gP14SD9w2-jI",
        "outputId": "bca13b2d-0d6e-4834-8a04-bb79786e050a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-16b3982bd5a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBagData\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BagData'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN32s(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "\n",
        "        score = self.bn1(self.relu(self.deconv1(x5)))     # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "metadata": {
        "id": "pWll02Ki3Dhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN16s(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "metadata": {
        "id": "H2Obgkpf3GLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCN8s(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
        "\n",
        "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "metadata": {
        "id": "1UUYod-k3ISz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCNs(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_net, n_class):\n",
        "        super().__init__()\n",
        "        self.n_class = n_class\n",
        "        self.pretrained_net = pretrained_net\n",
        "        self.relu    = nn.ReLU(inplace=True)\n",
        "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn1     = nn.BatchNorm2d(512)\n",
        "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn2     = nn.BatchNorm2d(256)\n",
        "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn3     = nn.BatchNorm2d(128)\n",
        "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn4     = nn.BatchNorm2d(64)\n",
        "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
        "        self.bn5     = nn.BatchNorm2d(32)\n",
        "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pretrained_net(x)\n",
        "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
        "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
        "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
        "        x2 = output['x2']  # size=(N, 128, x.H/4,  x.W/4)\n",
        "        x1 = output['x1']  # size=(N, 64, x.H/2,  x.W/2)\n",
        "\n",
        "        score = self.bn1(self.relu(self.deconv1(x5)))     # size=(N, 512, x.H/16, x.W/16)\n",
        "        score = score + x4                                # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
        "        score = self.bn2(self.relu(self.deconv2(score)))  # size=(N, 256, x.H/8, x.W/8)\n",
        "        score = score + x3                                # element-wise add, size=(N, 256, x.H/8, x.W/8)\n",
        "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
        "        score = score + x2                                # element-wise add, size=(N, 128, x.H/4, x.W/4)\n",
        "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
        "        score = score + x1                                # element-wise add, size=(N, 64, x.H/2, x.W/2)\n",
        "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
        "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
        "\n",
        "        return score  # size=(N, n_class, x.H/1, x.W/1)"
      ],
      "metadata": {
        "id": "rz7lUKNy3Kv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGNet(VGG):\n",
        "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
        "        super().__init__(make_layers(cfg[model]))\n",
        "        self.ranges = ranges[model]\n",
        "\n",
        "        if pretrained:\n",
        "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "        if not requires_grad:\n",
        "            for param in super().parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
        "            del self.classifier\n",
        "\n",
        "        if show_params:\n",
        "            for name, param in self.named_parameters():\n",
        "                print(name, param.size())\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = {}\n",
        "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
        "        for idx in range(len(self.ranges)):\n",
        "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
        "                x = self.features[layer](x)\n",
        "            output[\"x%d\"%(idx+1)] = x\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "QU0-rjkr3NlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranges = {\n",
        "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "cfg = {\n",
        "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}"
      ],
      "metadata": {
        "id": "4wvQGrmn3PtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "IT6-4aLu3Rxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "howIh2Wi2rDp",
        "outputId": "d5c8b0c4-1c80-46c1-d3dd-ca9f284027ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ebf4d37ef422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mBagData\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BagData'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    vis = visdom.Visdom()\n",
        "    vgg_model = VGGNet(requires_grad=True)\n",
        "    fcn_model = FCNs(pretrained_net=vgg_model, n_class=2)\n",
        "    fcn_model = fcn_model.cuda()\n",
        "    criterion = nn.BCELoss().cuda()\n",
        "    optimizer = optim.SGD(fcn_model.parameters(), lr=1e-2, momentum=0.7)\n",
        "    #input = torch.autograd.Variable(torch.randn(batch_size, 3, h, w))\n",
        "    #y = torch.autograd.Variable(torch.randn(batch_size, n_class, h, w), requires_grad=False)\n",
        "    saving_index =0\n",
        "    for epo in range(100):\n",
        "        saving_index +=1\n",
        "        index = 0\n",
        "        epo_loss = 0\n",
        "        start = time.time()\n",
        "        for item in dataloader:\n",
        "            index += 1\n",
        "            start = time.time()\n",
        "            input = item['A']\n",
        "            y = item['B']\n",
        "            input = torch.autograd.Variable(input)\n",
        "            y = torch.autograd.Variable(y)\n",
        "\n",
        "            input = input.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = fcn_model(input)\n",
        "            output = nn.functional.sigmoid(output)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            iter_loss = loss.data[0]\n",
        "            epo_loss += iter_loss\n",
        "            optimizer.step()\n",
        "\n",
        "            output_np = output.cpu().data.numpy().copy()\n",
        "            output_np = np.argmin(output_np, axis=1)\n",
        "            y_np = y.cpu().data.numpy().copy()\n",
        "            y_np = np.argmin(y_np, axis=1)\n",
        "            if np.mod(index, 20) ==1:\n",
        "                print('epoch {}, {}/{}, loss is {}'.format(epo, index, len(dataloader), iter_loss))\n",
        "                vis.close()\n",
        "                vis.images(output_np[:, None, :, :], opts=dict(title='pred')) \n",
        "                vis.images(y_np[:, None, :, :], opts=dict(title='label')) \n",
        "            #plt.subplot(1, 2, 1) \n",
        "            #plt.imshow(np.squeeze(y_np[0, :, :]), 'gray')\n",
        "            #plt.subplot(1, 2, 2) \n",
        "            #plt.imshow(np.squeeze(output_np[0, :, :]), 'gray')\n",
        "            #plt.pause(0.5)\n",
        "        print('epoch loss = %f'%(epo_loss/len(dataloader)))\n",
        "        \n",
        "        if np.mod(saving_index, 5)==1:\n",
        "            torch.save(fcn_model, 'checkpoints/fcn_model_{}.pt'.format(epo))\n",
        "            print('saveing checkpoints/fcn_model_{}.pt'.format(epo))"
      ]
    }
  ]
}